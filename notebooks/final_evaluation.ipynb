{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "'/data/ceph/hdd/project/node_07/ml4rg_students/2024/Project07_PolyB/Regulate-Me'"
                        ]
                    },
                    "execution_count": 44,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "import logging\n",
                "\n",
                "sys.path.append(\"../\")\n",
                "# put us into the base directory\n",
                "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
                "    os.chdir(\"../\")\n",
                "\n",
                "import hydra\n",
                "from omegaconf import DictConfig, OmegaConf\n",
                "import wandb\n",
                "import pandas as pd\n",
                "import torch\n",
                "from pytorch_lightning import Trainer\n",
                "from pytorch_lightning.loggers import WandbLogger\n",
                "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
                "\n",
                "from src.utils.preprocess import preprocess_data, get_tokens, validate_test_data\n",
                "from src.utils.utils import set_seed, setup_logger, count_parameters \n",
                "from src.training.data_module import YeastDataModule\n",
                "from src.models.bpnet import BPNet\n",
                "from src.models.transformer_lora import LoraBPNet\n",
                "from src.models.lora import Lora\n",
                "from src.training.loss import TotalBPNetLoss\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "set_seed(42)\n",
                "configs = ['config', 'lora', 'llm_bpnet']\n",
                "names = ['bpnet.ckpt', 'lora.ckpt', 'llm_bpnet.ckpt']\n",
                "model_metrics = {}\n",
                "os.getcwd()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_config(config_path: str, config_name: str) -> DictConfig:\n",
                "    with hydra.initialize(config_path=config_path, version_base=\"1.3\"):\n",
                "        config = hydra.compose(config_name=config_name)\n",
                "    return config\n",
                "\n",
                "\n",
                "def summarize_metrics(metrics):\n",
                "    summary = {}\n",
                "    for key, values in metrics.items():\n",
                "        if isinstance(values, list) and values and isinstance(values[0], (int, float)):\n",
                "            summary[key] = sum(values) / len(values)\n",
                "        else:\n",
                "            summary[key] = values\n",
                "    return summary\n",
                "\n",
                "\n",
                "def print_metrics(metrics):\n",
                "    print(\"\\nMetrics Summary:\")\n",
                "    metric_rows = []\n",
                "    for key, values in metrics.items():\n",
                "        if isinstance(values, list) and values and isinstance(values[0], (int, float)):\n",
                "            print(f\"{key}:\")\n",
                "            for i, value in enumerate(values):\n",
                "                print(f\"  Track {i+1}: {value:.4f}\")\n",
                "                metric_rows.append({\"metric\": key, \"track\": i + 1, \"value\": value})\n",
                "        else:\n",
                "            print(f\"{key}: {values}\")\n",
                "            metric_rows.append({\"metric\": key, \"track\": None, \"value\": values})\n",
                "    # print()\n",
                "    df_metrics = pd.DataFrame(metric_rows)\n",
                "    return df_metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to process each model\n",
                "def process_model(config_name, model_name):\n",
                "    config = load_config(config_path=\"../configs\", config_name=config_name)\n",
                "    set_seed(config.seed)\n",
                "\n",
                "    counts = torch.load(os.path.join(config.data.data_dir, config.data.counts_file))\n",
                "    dataset = pd.read_parquet(\n",
                "        os.path.join(config.data.data_dir, config.data.preprocessed_file)\n",
                "    )\n",
                "\n",
                "    train_idx, val_idx, test_idx, one_hots, counts, dataset = preprocess_data(\n",
                "        dataset,\n",
                "        counts,\n",
                "        config.data.restrict_seq_len,\n",
                "        config.data.seq_col,\n",
                "        set(config.data.val_chroms),\n",
                "        set(config.data.test_chroms),\n",
                "    )\n",
                "\n",
                "    if config.model_name != \"bpnet\":\n",
                "        output_seq_len = 300 - config.tokenizer.kmer_size + 1\n",
                "        counts = counts[:, :, :output_seq_len]\n",
                "        data = get_tokens(\n",
                "            dataset,\n",
                "            config.tokenizer.stride,\n",
                "            config.data.seq_col,\n",
                "            config.tokenizer.kmer_size,\n",
                "        )\n",
                "    else:\n",
                "        data = one_hots\n",
                "\n",
                "    data_module = YeastDataModule(\n",
                "        batch_size=config.training.batch_size,\n",
                "        train_idx=train_idx,\n",
                "        val_idx=val_idx,\n",
                "        test_idx=test_idx,\n",
                "        data=data,\n",
                "        counts=counts,\n",
                "    )\n",
                "\n",
                "    loss_fn = TotalBPNetLoss(\n",
                "        alpha=config.loss.alpha,\n",
                "        beta=config.loss.beta,\n",
                "        profile_loss_type=config.loss.profile_loss_type,\n",
                "        eps=config.loss.eps,\n",
                "    )\n",
                "\n",
                "    model_path = os.path.join(config.data.best_model_path, model_name)\n",
                "    if config.model_name == \"bpnet\":\n",
                "        model = BPNet.load_from_checkpoint(model_path)\n",
                "    elif config.model_name == \"llm_bpnet\":\n",
                "        model = LoraBPNet.load_from_checkpoint(model_path)\n",
                "    elif config.model_name == \"lora\":\n",
                "        model = Lora.load_from_checkpoint(model_path)\n",
                "    else:\n",
                "        raise ValueError(f\"Model {config.model_name} not recognized\")\n",
                "\n",
                "    model.eval()\n",
                "    data_module.setup()\n",
                "    test_data = data_module.test_dataloader()\n",
                "    metrics, loss = validate_test_data(model, test_data, loss_fn)\n",
                "\n",
                "    summarized_metrics = summarize_metrics(metrics)\n",
                "    df_metrics = pd.DataFrame(summarized_metrics, index=[config.model_name])\n",
                "    df_metrics[\"test_loss\"] = loss\n",
                "\n",
                "\n",
                "    return df_metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Loop over models and collect metrics\n",
                "def collect_all_metrics(configs, names):\n",
                "    all_metrics = pd.DataFrame()\n",
                "    for model_name, name in zip(configs, names):\n",
                "        df_metrics = process_model(model_name, name)\n",
                "        all_metrics = pd.concat([all_metrics, df_metrics])\n",
                "        print(f\"Model processed: {model_name} \")\n",
                "    return all_metrics"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Seed set to 42\n",
                        "Seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model processed: config \n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8d6d164027d14c3fa65932a0e2c49ff1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map (num_proc=4):   0%|          | 0/6580 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "test\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model processed: lora \n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "fc2597c1e2b44cea8bb517cc7623bf7d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map (num_proc=4):   0%|          | 0/6580 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "test\n",
                        "Model processed: llm_bpnet \n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>count_r2</th>\n",
                            "      <th>profile_pearson_median</th>\n",
                            "      <th>profile_pearson_mean</th>\n",
                            "      <th>profile_auprc</th>\n",
                            "      <th>profile_auroc</th>\n",
                            "      <th>test_loss</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>bpnet</th>\n",
                            "      <td>0.037942</td>\n",
                            "      <td>0.730465</td>\n",
                            "      <td>0.681940</td>\n",
                            "      <td>0.604532</td>\n",
                            "      <td>0.920428</td>\n",
                            "      <td>939.202738</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>lora</th>\n",
                            "      <td>0.103778</td>\n",
                            "      <td>0.809382</td>\n",
                            "      <td>0.738675</td>\n",
                            "      <td>0.639585</td>\n",
                            "      <td>0.931284</td>\n",
                            "      <td>711.484260</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>llm_bpnet</th>\n",
                            "      <td>0.028984</td>\n",
                            "      <td>0.771082</td>\n",
                            "      <td>0.702980</td>\n",
                            "      <td>0.623123</td>\n",
                            "      <td>0.925758</td>\n",
                            "      <td>844.047709</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "           count_r2  profile_pearson_median  profile_pearson_mean  \\\n",
                            "bpnet      0.037942                0.730465              0.681940   \n",
                            "lora       0.103778                0.809382              0.738675   \n",
                            "llm_bpnet  0.028984                0.771082              0.702980   \n",
                            "\n",
                            "           profile_auprc  profile_auroc   test_loss  \n",
                            "bpnet           0.604532       0.920428  939.202738  \n",
                            "lora            0.639585       0.931284  711.484260  \n",
                            "llm_bpnet       0.623123       0.925758  844.047709  "
                        ]
                    },
                    "execution_count": 48,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "all_model_metrics = collect_all_metrics(configs, names)\n",
                "all_model_metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_model_metrics.drop(\n",
                "    columns=[\"count_r2\"], inplace=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Pearson Median</th>\n",
                            "      <th>Pearson Mean</th>\n",
                            "      <th>AUPRC</th>\n",
                            "      <th>AUROC</th>\n",
                            "      <th>Test Loss</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>BPNet</th>\n",
                            "      <td>0.730465</td>\n",
                            "      <td>0.681940</td>\n",
                            "      <td>0.604532</td>\n",
                            "      <td>0.920428</td>\n",
                            "      <td>939.202738</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>SpeciesLM + LoRA</th>\n",
                            "      <td>0.809382</td>\n",
                            "      <td>0.738675</td>\n",
                            "      <td>0.639585</td>\n",
                            "      <td>0.931284</td>\n",
                            "      <td>711.484260</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>SpeciesLM</th>\n",
                            "      <td>0.771082</td>\n",
                            "      <td>0.702980</td>\n",
                            "      <td>0.623123</td>\n",
                            "      <td>0.925758</td>\n",
                            "      <td>844.047709</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                  Pearson Median  Pearson Mean     AUPRC     AUROC   Test Loss\n",
                            "BPNet                   0.730465      0.681940  0.604532  0.920428  939.202738\n",
                            "SpeciesLM + LoRA        0.809382      0.738675  0.639585  0.931284  711.484260\n",
                            "SpeciesLM               0.771082      0.702980  0.623123  0.925758  844.047709"
                        ]
                    },
                    "execution_count": 50,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "all_model_metrics.columns = [\"Pearson Median\", \"Pearson Mean\" ,\"AUPRC\", \"AUROC\" ,\"Test Loss\"]\n",
                "all_model_metrics.index = [\"BPNet\", \"SpeciesLM + LoRA\", \"SpeciesLM\"]\n",
                "all_model_metrics\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [],
            "source": [
                "# make folder figures\n",
                "os.makedirs(\"./data/figures\", exist_ok=True)\n",
                "all_model_metrics.to_latex(\"./data/figures/all_model_metrics.tex\", index=True, float_format=\"%.3f\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "regulate-me",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
